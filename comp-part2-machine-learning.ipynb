{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Machine Learning\n",
    "Eric Pahl\n",
    "\n",
    "The line of questioning for this part of Eric Pahl’s comprehensive exam probes the depth of his understanding related to common assertions made about random decision forest.\n",
    "\n",
    "## Problem 2.1: Implementation\n",
    "\n",
    "Gini Impurity Index is a standard criterion used when constructing individual decision trees for a random forest implementation. Reusing the data set “ExampleData.csv” provided in Part 1, but now assuming that this data set represents a retrospective observational study that records which treatments a physician chooses based on the other variables.  For Part 2, interpret the variables as:\n",
    "\n",
    "|Variable name|Data Type|Description|\n",
    "|-------------|---------|-----------|\n",
    "|Treatment<br>(output category)|Categorical|A: Branded drug <br>B: Generic Drug|\n",
    "|Age|Integer|Age in years after birth|\n",
    "|Sex|Categorical|M: Male,<br> F: Female|\n",
    "|OverallHealthIdx|Integer|Score from a self-reported questionnaire|\n",
    "|Time|Integer|Number of hours since emergency room admission|\n",
    "|Censored <br>(poorly named variable)|Categorical|The identifier of the physician type:<br>0: Internal Medicine doctor, <br>1: Family Medicine doctor|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Create a fork of the code associated with the article (https://github.com/joachimvalente/decision-tree-cart) for the modifications.  Store the results of part1 under your forked repositories branch named “part1_comps”.\n",
    "Done. See https://github.com/ericpahl/decision-tree-cart/tree/part1_comps.\n",
    "\n",
    "### b)\tModify the source code to generate a pictorial representation of the tree associated with applying the described algorithm to the data provided using a maximum tree depth of 1,000,000.\n",
    "Carefully report the data manipulations or code modifications that are necessary to complete this task.  It is *NOT* acceptable to pre-process or modify the input data outside of this codebase.  The resulting changes needed to investigate the newly provided data set should not break the existing functionality of the program.\n",
    "\n",
    "1. I read the Cart.py documentation and ran the main function to confirm it was working in its default configuration with prespecified datasets (iris, wifi, and breast).\n",
    "1. I noticed that ExampleData.csv included incompatible datatypes like char and str when only numeric data were acceptable for the DecisionTreeClassifier.\n",
    "1. I created two checks and conversions in the fit function within DecisionTreeClassifier code cart.py. \n",
    "    1. Convert the outcome varible to numeric 0 to n-1\n",
    "    1. Convert binary str variables to 0 and 1\n",
    "1. I ran the main function again to make sure that I did not break any existing functionality required for iris, breast, and wifi.\n",
    "1. I fit the ExampleData successfully with max_depth 1,000,000 and used the debug function to print the tree. Unfortunately, this is an wieldly output and is difficult to see. I've created a video that helps explain what is going on, available here: https://www.loom.com/share/08580ccf1f2b4e62bab8fd03c096d422\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>OverallHealthIdx</th>\n",
       "      <th>Time</th>\n",
       "      <th>Censored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>95</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>67</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treatment  Age Sex  OverallHealthIdx  Time  Censored\n",
       "0         A   95   M                56    39         1\n",
       "1         A   85   M                66    37         1\n",
       "2         A   73   F                67    39         1\n",
       "3         A   62   M                39    23         0\n",
       "4         A   62   M                92    29         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip3 install pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cart\n",
    "import categorical_gini\n",
    "import continuous_gini\n",
    "import minimal_cart\n",
    "import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('~/ExampleData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>OverallHealthIdx</th>\n",
       "      <th>Time</th>\n",
       "      <th>Censored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.220000</td>\n",
       "      <td>32.245000</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.285692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.213113</td>\n",
       "      <td>9.092212</td>\n",
       "      <td>0.481205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Treatment         Age  Sex  OverallHealthIdx        Time    Censored\n",
       "count        200  200.000000  200        200.000000  200.000000  200.000000\n",
       "unique         2         NaN    2               NaN         NaN         NaN\n",
       "top            B         NaN    M               NaN         NaN         NaN\n",
       "freq         100         NaN  105               NaN         NaN         NaN\n",
       "mean         NaN   77.200000  NaN         67.220000   32.245000    0.360000\n",
       "std          NaN   11.285692  NaN         15.213113    9.092212    0.481205\n",
       "min          NaN   48.000000  NaN         35.000000   14.000000    0.000000\n",
       "25%          NaN   70.000000  NaN         55.750000   25.000000    0.000000\n",
       "50%          NaN   78.000000  NaN         67.000000   31.000000    0.000000\n",
       "75%          NaN   85.000000  NaN         76.000000   39.000000    1.000000\n",
       "max          NaN  112.000000  NaN        115.000000   63.000000    1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "arr = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "X = arr[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcome\n",
    "y = arr[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier per max_depth\n",
    "clf = cart.DecisionTreeClassifier(max_depth=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier with predictors and outcome\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# print the tree\n",
    "clf.debug(list(df.columns[1:]),\n",
    "          list(list(np.unique(df['Treatment']))),\n",
    "          False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\tIn your report, describe the Gini impurity Index, including its origins, intuitive meaning, and mathematical implementation.\n",
    "There are two common splitting criteria for nodes when training decision-tree-based classifiers, Gini Index and Information Gain. The Gini Impurity Index (gini) is a simple measure of impurity in a set of observations. The gini was introduced in the early 20th century by Corrado Gini. \n",
    "\n",
    "Intuitively, gini is the chance of incorrectly classifying any given observations in the set. If there is a 50/50 split, then the gini is $0.5$. If there is a 75/25 split, then the gini is calculated by adding the incorrect probabilites, $0.75 * 0.25 + 0.25 * 0.75 = 0.375$ the impurity is reduced when the set becomes more homogeneous. The equation is $gini = \\sum^C_{i=1} p(i) * (1-p(i))$ where $C$ is number of classes and $p(i)$ is the probability of picking an observation with class $i$.\n",
    "\n",
    "\n",
    "### d)\tProvide a simple function implementing the mathematical formulation of the Gini impurity Index that computes the Gini impurity index\n",
    "In the Python programming language, in a new file named \"categorical_gini.py\" under the “part1_comps” branch.  Report the Gini impurity index for the categorical variables [\"Sex,\" \"Censored\"] with respect to Treatment variable in the table above. The resulting code must be well documented and easy to understand by other non-expert programmers. Report any assumptions or limitations to apply this function.  \n",
    "\n",
    "For the categorical_gini.py function, there are some assumptions and limitations. This function is only appropriate for binary categorical variables and categorical outcomes. The function assumes that there will be three inputs, an __X__ numpy array of observations (row) and variables (columns), __y__ vector of outcomes, and __varIdx__ the column index of __X__ of the variable in question to calculate the gini index. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex Gini: 0.4999496234320136\n",
      "Censored Gini: 0.48755711684992287\n"
     ]
    }
   ],
   "source": [
    "import categorical_gini as cat_gini\n",
    "\n",
    "# index of variable to calculate\n",
    "sexIdx = 1       # idx is 1 for Sex\n",
    "censoredIdx = 4  # idx is 4 for Censored\n",
    "\n",
    "print(\"Sex Gini: \" + str(cat_gini.categorical_gini(X,y,sexIdx)))\n",
    "print(\"Censored Gini: \" + str(cat_gini.categorical_gini(X,y,censoredIdx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\tProvide a simple function implementing the mathematical formulation for identifying both the optimal Gini impurity index and the threshold for optimality of a continuous variable.\n",
    "In the Python programming language, in a new file named \"continuous_gini.py\" under the “part1_comps” branch.  Report both the optimal Gini impurity index and the associated threshold for the categorical variables [\"Age,\" \"OverallHealthIdx,\" \"Time\"] with respect to Treatment in the table above. The resulting code must be well documented and easy to understand by other non-expert programmers. Report any assumptions or limitations to apply this function.\n",
    "\n",
    "For the continuous_gini.py function, there are some assumptions and limitations. This function is only appropriate for continuous variables and categorical outcomes. The function assumes that there will be three inputs, an __X__ numpy array of observations (row) and variables (columns), __y__ vector of outcomes, and __varIdx__ the column index of __X__ of the variable in question to calculate the gini index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age (Gini,Threshold): (0.4892307692307692, 82.5)\n",
      "OverallHealthIdx (Gini,Threshold): (0.4899218428630194, 90.5)\n",
      "Time (Gini,Threshold): (0.4695495495495496, 46.5)\n"
     ]
    }
   ],
   "source": [
    "import continuous_gini as cont_gini\n",
    "# index of variable to calculate\n",
    "TimeIdx = 3       # idx is 3 for Time\n",
    "AgeIdx = 0       # idx is 0 for Age\n",
    "OverallHealthIdx = 2 # idx is 2 for overallhealthidx\n",
    "\n",
    "print(\"Age (Gini,Threshold): \" + str(cont_gini.continuous_gini(X,y,AgeIdx)))\n",
    "print(\"OverallHealthIdx (Gini,Threshold): \" + str(cont_gini.continuous_gini(X,y,OverallHealthIdx)))\n",
    "print(\"Time (Gini,Threshold): \" + str(cont_gini.continuous_gini(X,y,TimeIdx)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2: Assumptions, Limitations, and Generalization\n",
    "A model generated with the program in Part 2.1 can be used to predict outcomes given a set of input variables [“Age\", \"Sex”, “OverallHealthIdx”, “Time\", \"Censored”].  Assume that the provided 200 sample dataset ‘ExampleData.csv’ is the initial public release of data to be used for developing a predictive model to be submitted for evaluation on a large private dataset of 5 million samples.  Create a new branch called “part2_comps” for any changes made in this section.\n",
    "\n",
    "\n",
    "### a)\tFor the model generated with a tree depth of 1,000,000, what is the accuracy of the model for the ‘ExampleData.csv’ dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 100.0%\n",
      "Testing Accuracy = 53.06122448979592%\n"
     ]
    }
   ],
   "source": [
    "# create training and testing subsets\n",
    "arr = df.to_numpy()\n",
    "# shuffle rows\n",
    "np.random.shuffle(arr)\n",
    "# predictors\n",
    "X = arr[:,1:]\n",
    "# outcome\n",
    "y = arr[:,0]\n",
    "# train on first 150 observation\n",
    "# :150\n",
    "\n",
    "# test on the rest\n",
    "# 151:\n",
    "\n",
    "# create the classifier per max_depth\n",
    "clf = cart.DecisionTreeClassifier(max_depth=1000000)\n",
    "\n",
    "clf.fit(X[:151,:],y[:151])\n",
    "\n",
    "# predict train values\n",
    "y0 = clf.predict(X[:151,:])\n",
    "\n",
    "# calculate training accuracy\n",
    "print(\"Training Accuracy = \"+str(np.mean(y0 == y[:151])*100) + \"%\")\n",
    "\n",
    "# predict test values\n",
    "y1 = clf.predict(X[151:,:])\n",
    "\n",
    "# calculate testing accuracy\n",
    "print(\"Testing Accuracy = \"+str(np.mean(y1 == y[151:])*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing accuracy for the model are different because the model is clearly overfit with a max depth of 1M and only 200 total observations. The test was a subset of the data held out during the training process and then used to test the model for applicability on data. We used a heldout set of 50 observations (25% of the example) to represent the 5 million samples available in the private dataset. Since these samples aren't used in the training we can assume that the classifier is likely to perform similar to the Test accuracy when applied to the private data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b)\tCreate models for various maximum depths and report (both graphically and in prose) on the effect of tree depth on the accuracy of the models with respect to the 200 samples provided in ‘ExampleData.csv’ data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = [1,2,3,5,8,10,25,75,150,1000,10000,100000,1000000]\n",
    "\n",
    "accu = []\n",
    "\n",
    "for i in range(len(max_depths)):\n",
    "    clftmp = cart.DecisionTreeClassifier(max_depth=max_depths[i])\n",
    "    clftmp.fit(X[:150,:],y[:150])\n",
    "    ytmp = clftmp.predict(X[150:,:])\n",
    "    accu.append(np.mean(ytmp == y[150:]))\n",
    "    \n",
    "plt.plot(max_depths,accu)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown in the figure above, the test accuracy levels out as Max Depth gets larger and there is no benefit after 100 for this situation. Since the test set is only 25% of the ExampleData and only 50 samples, each time this experiment is executed the random \"shuffle\" of the variables changes the results for max depths less than 50. \n",
    "\n",
    "### c)\tUsing the algorithm completed for Part A, describe a process that will generate a better model for predicting the private evaluation data set.\n",
    "In the describing the approach, include a details about the process, assumptions that are made about both the model and data characteristics, methods for evaluating criteria, and any other support justifying the assertion that this new model configuration would be applicable to the larger dataset, and any other support.\n",
    "\n",
    "This model is significantly overtrained. With a max depth of 1000000, the decision tree is capable of uniquely classifying every single observation in the 200 observations. In order to build a model that translates better to a larger dataset or a different dataset we must separate the training, validation, and testing samples. This contrast what has been done in 2.2a because the training and testing data were the same, using a held out validation or testing dataset that is not used during training will promote better translation to new obserations, in this case, the larger private dataset.\n",
    "\n",
    "Another option is to use 10-fold cross-validation where the average testing accuracy over 10 experiments with 10 folds (10%) of the ExampleData used for each respective experiment. This provides a way to estimate a better test accuracy considering an application on a much larger private dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 k-fold cross validation\n",
    "k = 10\n",
    "\n",
    "# fold size\n",
    "fold = int(len(y)/k)\n",
    "\n",
    "ksets = range(fold, len(y), fold)\n",
    "\n",
    "test_acc = []\n",
    "\n",
    "clftmp = cart.DecisionTreeClassifier(max_depth=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first fold: 0.45\n",
      "middle fold: 0.4\n",
      "middle fold: 0.7\n",
      "middle fold: 0.5\n",
      "middle fold: 0.5\n",
      "middle fold: 0.55\n",
      "middle fold: 0.6\n",
      "middle fold: 0.4\n",
      "middle fold: 0.3\n",
      "last fold: 0.5111111111111111\n",
      "10-fold cross validation accuracy is: 0.49111111111111105\n"
     ]
    }
   ],
   "source": [
    "for i in ksets:\n",
    "    # first fold\n",
    "    if i == fold:\n",
    "        clftmp.fit(X[:len(y)-i,:],y[:len(y)-i])\n",
    "        ytmp = clftmp.predict(X[len(y)-i:,:])\n",
    "        meantmp = np.mean(ytmp == y[len(y)-i:])\n",
    "        test_acc.append(meantmp)\n",
    "        print(\"first fold: \"+str(meantmp))\n",
    "    # last fold\n",
    "    if i == len(y)-fold:\n",
    "        clftmp.fit(X[i:,:],y[i:])\n",
    "        ytmp = clftmp.predict(X[:i,:])\n",
    "        meantmp = np.mean(ytmp == y[:i])\n",
    "        test_acc.append(meantmp)\n",
    "        print(\"last fold: \"+str(meantmp))\n",
    "    # middle fold\n",
    "    else:\n",
    "        # before and after folds must be concatenated\n",
    "        midX = np.concatenate([X[:i-fold,:],X[i:,:]])\n",
    "        midy = np.concatenate([y[:i-fold],y[i:]])\n",
    "        clftmp.fit(midX,midy)\n",
    "        ytmp = clftmp.predict(X[i-fold:i,:])\n",
    "        meantmp = np.mean(ytmp == y[i-fold:i])\n",
    "        test_acc.append(meantmp)\n",
    "        print(\"middle fold: \"+str(meantmp))\n",
    "    \n",
    "print(str(k)+\"-fold cross validation accuracy is: \"+str(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.3: Interpretation\n",
    "Now consider the extension of decision trees into the random forest (RF) ensemble prediction method. \n",
    "\n",
    "Describe the original RF algorithm. \n",
    "\n",
    "  - The original RF algorithm was described by Leo Breiman in 2001. The RF algorithm combines the following concepts: Ensemble, bagging, and random split selection for decision trees. \n",
    "  - Use of the Strong Law of Large Numbers shows that they always converge so that overfitting is not a problem. The accuracy of a random forest depends on the strength of the individual tree classifiers and a measure of the dependence between them.\n",
    "  - The random selection of features at each node to determine the split. An important question is how many features to select at each node. Two different forms of random features. The first uses random selection from the original inputs; the second uses random linear combinations of inputs. \n",
    "  - Bagging is used with random feature selection and these nicely complement each other. Bagging increases accuracy when random features are used and bagging can give out of bag estimates for generalizing error. Bagged classifiers have demonstrated empirically that out of bag estimates are as accurate as using a test set of the same size of the training set (basically, you need 1/2 as much data!).\n",
    "  - For my qualifier exam (Spring 2017), I created two slides (9 and 10) that illustrate the RF algorithm available here: https://iowa-my.sharepoint.com/:p:/g/personal/epahl_uiowa_edu/Eb_o2xoTmmJAkLTh28rLDhwBUEI_-on8DKYX11Pfi2COMQ?e=JIKkKw.\n",
    "  - \n",
    "\n",
    "What specific advantages and disadvantages does it have over decision trees, and in general over other competitor methods? \n",
    "\n",
    "  - \n",
    "\n",
    "Examine the generalization capabilities of the RF algorithm, both theoretically (in light of the bias-variance trade-off and the strength-diversity decomposition for ensembles) and in practice (using comparative literature review). \n",
    "\n",
    "On what sorts of datasets should the algorithm be expected to perform particularly well, relative to other state-of-the-art classification algorithms? \n",
    "\n",
    "In what ways (if any) can an RF model be interpreted, or its predictions be explained? \n",
    "\n",
    "Finally, how do decision trees (and therefore random forests) deal with missing feature values? \n",
    "\n",
    "In what way would you expect this mechanism to affect the performance of the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
